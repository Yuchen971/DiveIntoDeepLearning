{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "linear_regression_gradient_descent.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObz1/YanTFk4DoRPAWNP4q"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xUQeXcM-QZjq"
      },
      "outputs": [],
      "source": [
        "#!pip install d2l\n",
        "import torch\n",
        "import random\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 构造数据集\n",
        "生成一个包含1000个样本的数据集,每个样本包含从 standard normal distribution 中采样的2个特征\n",
        "数据集为矩阵:\n",
        "$$\\mathbf{X} \\in \\mathbb{R}^{1000*2}$$\n",
        "模型为\n",
        "$$\\mathbf{y} = \\mathbf{Xw}+b+ϵ$$\n",
        "模型参数 $\\mathbf{w} = [2, -3.4]^{\\top}, b = 4.2$"
      ],
      "metadata": {
        "id": "ZgkHJtlcOFsR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def synthetic_data(w, b, num_examples):\n",
        "  X = torch.normal(0, 1, (num_examples, len(w)))\n",
        "  # X's shape is (1000, 2)\n",
        "  y = torch.matmul(X, w) + b\n",
        "  y += torch.normal(0, 0.01, y.shape)\n",
        "  return X, y.reshape(-1, 1) # 标量 -> 向量"
      ],
      "metadata": {
        "id": "KcuZXc0OVn4M"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_w = torch.tensor([2, -3.4])\n",
        "true_b = 4.2\n",
        "features, labels = synthetic_data(true_w, true_b, 1000)"
      ],
      "metadata": {
        "id": "-qEuevE3K9uq"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 读取数据集"
      ],
      "metadata": {
        "id": "y1EuMdOJR20J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 打乱数据集, 小批量获取\n",
        "def data_iter(batch_size, features, labels):\n",
        "  num_examples = len(features) #1000\n",
        "  indices = list(range(num_examples))\n",
        "  random.shuffle(indices)\n",
        "  for i in range(0, num_examples, batch_size):\n",
        "    batch_indices = torch.tensor(\n",
        "        indices[i: min(i+batch_size, num_examples)]\n",
        "    )\n",
        "    yield features[batch_indices], labels[batch_indices]"
      ],
      "metadata": {
        "id": "ztJFFTaxR2gy"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 10\n",
        "for X, y in data_iter(batch_size, features, labels):\n",
        "  print(X, '\\n', y)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvUxPTAbSQ9M",
        "outputId": "d4a8e949-7282-4c17-df7e-42258289a7d4"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.3049, -0.4945],\n",
            "        [-1.6132, -0.4637],\n",
            "        [ 0.2183, -1.6855],\n",
            "        [ 0.4436, -0.0314],\n",
            "        [-1.1163,  0.3185],\n",
            "        [-0.4928, -0.0727],\n",
            "        [ 0.0995, -0.0180],\n",
            "        [ 0.0114,  0.2692],\n",
            "        [ 0.5284,  1.4269],\n",
            "        [-2.4745, -0.5959]]) \n",
            " tensor([[ 8.5030],\n",
            "        [ 2.5620],\n",
            "        [10.3623],\n",
            "        [ 5.1965],\n",
            "        [ 0.8771],\n",
            "        [ 3.4431],\n",
            "        [ 4.4489],\n",
            "        [ 3.2862],\n",
            "        [ 0.4145],\n",
            "        [ 1.2907]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 初始化权重和偏置\n",
        "任务为更新这些参数, 直到参数足够拟合数据"
      ],
      "metadata": {
        "id": "dDpi_IQhkKCN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = torch.normal(0, 0.01, size=(2,1), requires_grad=True)\n",
        "b = torch.zeros(1, requires_grad=True)"
      ],
      "metadata": {
        "id": "4qWpf2FehQHA"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定义模型和 loss function"
      ],
      "metadata": {
        "id": "FW-ZxGdOlHvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def linreg(X, w, b):\n",
        "  return torch.matmul(X, w) + b\n",
        "\n",
        "def squared_loss(y_hat, y):\n",
        "  return (y_hat - y.reshape(y_hat.shape))**2/2"
      ],
      "metadata": {
        "id": "3X6GXNVNkfMP"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 定义优化算法\n",
        "使用 SGD 算法更新参数, 每一步更新的大小由学习率决定\n",
        "\n",
        "用批量大小(batch_size)来规范化步⻓，这样步⻓大小就不会取决于我们对批量大小的选择"
      ],
      "metadata": {
        "id": "hk_K5gUflaSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(params, lr, batch_size):\n",
        "  with torch.no_grad(): # don't record grad, 此函数只负责更新param\n",
        "    for param in params:\n",
        "      param -= lr * param.grad / batch_size\n",
        "      param.grad.zero_() # set grad to 0"
      ],
      "metadata": {
        "id": "BMgxFa9Fl6M5"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练\n",
        "步骤:\n",
        "- 每次迭代读取小批量训练样本\n",
        "- 通过模型或得一组预测\n",
        "- 计算损失\n",
        "- 反向传播, 储存每个参数的梯度\n",
        "- 调用优化算法来更新模型参数\n",
        "\n",
        "概括\n",
        "- 初始化参数\n",
        "- 重复以下训练直到完成\n",
        "  - 计算梯度 ($\\nabla$) $$\n",
        "\\mathbf{g} \\leftarrow \\partial_{(\\mathbf{w}, b)} \\frac{1}{|\\mathcal{B}|} \\sum_{i \\in \\mathcal{B}} l\\left(\\mathbf{x}^{(i)}, y^{(i)}, \\mathbf{w}, b\\right)\n",
        "$$\n",
        "  - 更新参数$$\n",
        "(\\mathbf{w}, b) \\leftarrow(\\mathbf{w}, b)-\\eta \\mathbf{g}\n",
        "$$"
      ],
      "metadata": {
        "id": "gRrxPjLAu8BO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.03\n",
        "num_epochs = 3 # 迭代周期个数\n",
        "net = linreg\n",
        "loss = squared_loss\n",
        "for epoch in range(num_epochs):\n",
        "  for X, y in data_iter(batch_size, features, labels):\n",
        "    l = loss(net(X, w, b), y) # X 和 y 的小批量损失\n",
        "    # l 的形状是(batch_size, 1), 而不是一个标量\n",
        "    # 所以l中的所有元素被加到一起(也就是乘单位向量, 对梯度无影响)\n",
        "    # 以此计算[w, b]的梯度\n",
        "    l.sum().backward()\n",
        "    sgd([w,b], lr, batch_size) # 更新参数\n",
        "  with torch.no_grad():\n",
        "    train_l = loss(net(features, w, b), labels)\n",
        "    print(f'epoch {epoch + 1}, loss {float(train_l.mean()):f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJVRbvmOyPjY",
        "outputId": "ea6b396c-7389-4a5a-930e-02000a3a56bd"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1, loss 0.000054\n",
            "epoch 2, loss 0.000054\n",
            "epoch 3, loss 0.000054\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'w的估计误差: {true_w - w.reshape(true_w.shape)}') \n",
        "print(f'b的估计误差: {true_b - b}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NujTZ-K12jbp",
        "outputId": "0243e524-b708-4b88-b0e1-a0c9770507d7"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "w的估计误差: tensor([-0.0007,  0.0009], grad_fn=<SubBackward0>)\n",
            "b的估计误差: tensor([0.0008], grad_fn=<RsubBackward1>)\n"
          ]
        }
      ]
    }
  ]
}