{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Softmax_refine.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP3qri/FwhN+rTXt9GG5OJY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuchen971/DiveIntoDeepLearning/blob/main/Linear_Neural_Networks/Softmax.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tOjY7eDIJTv"
      },
      "outputs": [],
      "source": [
        "!pip install d2l"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "import torchvision\n",
        "from torch.utils import data\n",
        "from torchvision import transforms \n",
        "from d2l import torch as d2l"
      ],
      "metadata": {
        "id": "jI8N_rrqIPE-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fashion_mnist_labels(labels): \n",
        "  \"\"\"返回Fashion-MNIST数据集的文本标签\"\"\"\n",
        "  text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',\n",
        "                  'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot'] \n",
        "  return [text_labels[int(i)] for i in labels]\n",
        "\n",
        "def get_data_loader_workers():\n",
        "  return 4 # 使用四个进程\n",
        "\n",
        "def load_data_fashion_mnist(batch_size, resize = None):\n",
        "  '''\n",
        "  load_data_fashion_mnist函数\n",
        "  用于获取和读取Fashion-MNIST数据集\n",
        "  返回训练集和验证集的数据迭代器\n",
        "  '''\n",
        "  # ToTensor PIL (H*W*C) in [0,255] \n",
        "  # -> torch.Tensor (C*H*W) in [0.0, 1.0]\n",
        "  trans = [transforms.ToTensor()] # trans is a list\n",
        "  if resize:\n",
        "    # insert new transformer into the trans list\n",
        "    trans.insert(0, transforms.Resize(resize))\n",
        "  # 串联多个图片变换的操作, 也就是串联trans的list\n",
        "  trans = transforms.Compose(trans)\n",
        "  mnist_train = torchvision.datasets.FashionMNIST(\n",
        "      root=\"../data\", train=True, transform = trans, download=True\n",
        "  )\n",
        "  mnist_test = torchvision.datasets.FashionMNIST(\n",
        "      root=\"../data\", train=False, transform = trans, download=True\n",
        "  )\n",
        "  return (data.DataLoader(mnist_train, batch_size, shuffle=True,\n",
        "                          num_workers=get_data_loader_workers()),\n",
        "          data.DataLoader(mnist_test, batch_size, shuffle=False,\n",
        "                          num_workers = get_data_loader_workers()))\n"
      ],
      "metadata": {
        "id": "UwJX76pbIZRK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "num_epochs = 10\n",
        "lr = 0.1\n",
        "train_iter, test_iter = load_data_fashion_mnist(batch_size)\n",
        "num_inputs = 784\n",
        "num_outputs = 10\n",
        "W = torch.normal(0, 0.01, size=(num_inputs, num_outputs), requires_grad=True) \n",
        "b = torch.zeros(num_outputs, requires_grad=True)\n",
        "\n",
        "def softmax(X):\n",
        "  X_exp = torch.exp(X)\n",
        "  partition = X_exp.sum(1, keepdim=True)\n",
        "  return X_exp / partition # 这里使用广播机制\n",
        "  # ([256, 10]) / ([256, 1]) => ([256, 10])\n",
        "\n",
        "# 这里X变为(256, 784) 其中256是batch_size, 784是图片拉长的维度\n",
        "# 也就是每一行一个被拉长的图片, 784个像素点feature, 有256张\n",
        "# W维度为(784, 10), 相乘得到的维度为 (256, 10), 也就是每一张图片的十种类别的概率\n",
        "def net(X):\n",
        "  return softmax(\n",
        "      torch.matmul(X.reshape(-1, W.shape[0]), W) + b\n",
        "  )\n",
        "\n",
        "def cross_entropy(y_hat, y):\n",
        "  '''\n",
        "  y = torch.tensor([0, 2])\n",
        "  y_hat = torch.tensor([[0.1, 0.3, 0.6],[0.3, 0.2, 0.5]])\n",
        "  cross_entropy(y_hat, y)\n",
        "  '''\n",
        "  return -torch.log(y_hat[range(len(y_hat)), y])\n",
        "\n",
        "def accuracy(y_hat, y):\n",
        "  if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "    y_hat = y_hat.argmax(axis=1) # 每行中最大元素的索引来获得预测类别\n",
        "  # 将y_hat的数据类型转换为与y的数据类型, 一个32, 一个64\n",
        "  cmp = y_hat.type(y.dtype) == y \n",
        "  # 将 TRUE, FALSE -> 0, 1\n",
        "  return float(cmp.type(y.dtype).sum()) #return 正确的个数\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dRvVmSEKHZ1",
        "outputId": "d7b11d47-2e50-428c-ccd2-3b952384886e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Accumulator:\n",
        "  '''对n个变量叠加'''\n",
        "  def __init__(self, n):\n",
        "    self.data = [0.0] * n # 初始化n个数\n",
        "  def add(self, *args):\n",
        "    # 元素相加\n",
        "    self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "  def reset(self):\n",
        "    self.data = [0.0] * len(self.data)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]\n",
        "\n",
        "def evaluate_accuracy(net, data_iter):\n",
        "  if isinstance(net, torch.nn.Module):\n",
        "    net.eval() # 评估模式\n",
        "  metric = Accumulator(2) # 初始化累加的两个参数\n",
        "  with torch.no_grad():\n",
        "    for X, y in data_iter:\n",
        "      # y.numel(): return the length (总数)\n",
        "      metric.add(accuracy(net(X), y), y.numel())\n",
        "  return metric[0] / metric[1] # 正确的个数除以总数"
      ],
      "metadata": {
        "id": "J3iVNcqBZAqi"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch_ch3(net, train_iter, loss, updater):\n",
        "  '''训练模型一个迭代周期, updater: optimizer'''\n",
        "  if isinstance(net, torch.nn.Module):\n",
        "    net.train()\n",
        "  # 训练损失总和、训练准确度总和、样本数初始化\n",
        "  metric = Accumulator(3)\n",
        "  for X, y in train_iter:\n",
        "    # 计算梯度\n",
        "    y_hat = net(X) # 预测值输出: ([256, 10])\n",
        "    l = loss(y_hat, y) # cross entropy\n",
        "    if isinstance(updater, torch.optim.Optimizer):\n",
        "      # 使用PyTorch内置的优化器和损失函数\n",
        "      updater.zero_grad()\n",
        "      l.backward()\n",
        "      updater.step()\n",
        "    else:\n",
        "      # 使用定制的优化器和损失函数\n",
        "      l.sum().backward() # l是向量, 转换为标量, pytorch自动转换\n",
        "      updater(X.shape[0]) # X.shape 也就是 batch_size, 因为拉长了\n",
        "    metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
        "  # 返回训练损失和训练精度\n",
        "  return metric[0] / metric [2], metric[1] / metric [2]"
      ],
      "metadata": {
        "id": "rT1lbC5Q-SBB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(params, lr, batch_size):\n",
        "  with torch.no_grad(): # don't record grad, 此函数只负责更新param\n",
        "    for param in params:\n",
        "      param -= lr * param.grad / batch_size\n",
        "      param.grad.zero_() # set grad to 0\n",
        "def updater(batch_size):\n",
        "  return sgd([W,b], lr, batch_size)\n",
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n",
        "  for epoch in range(num_epochs):\n",
        "    train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
        "    test_acc = evaluate_accuracy(net, test_iter)\n",
        "    train_loss, train_acc = train_metrics\n",
        "    print(f'train_loss = {train_loss}, train_acc = {train_acc}, test_acc = {test_acc}')\n",
        "\n",
        "train_ch3(net,\n",
        "          train_iter,\n",
        "          test_iter,\n",
        "          cross_entropy,\n",
        "          num_epochs,\n",
        "          updater)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ptF9X1igB0NG",
        "outputId": "e40efb3c-f02b-4c0b-e3dc-d69f89112bd2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss = 0.7861420282363891, train_acc = 0.7485666666666667, test_acc = 0.7889\n",
            "train_loss = 0.5708365582148234, train_acc = 0.81365, test_acc = 0.8062\n",
            "train_loss = 0.5259884218215942, train_acc = 0.8245833333333333, test_acc = 0.8161\n",
            "train_loss = 0.5013544778188069, train_acc = 0.8317166666666667, test_acc = 0.8066\n",
            "train_loss = 0.4739455588658651, train_acc = 0.8403666666666667, test_acc = 0.8264\n",
            "train_loss = 0.46448530502319335, train_acc = 0.8438, test_acc = 0.8023\n",
            "train_loss = 0.4585993151982625, train_acc = 0.8444666666666667, test_acc = 0.8267\n",
            "train_loss = 0.4526930679321289, train_acc = 0.8451666666666666, test_acc = 0.829\n",
            "train_loss = 0.4478394233703613, train_acc = 0.8479, test_acc = 0.8356\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_ch3(net, test_iter, n = 6):\n",
        "  for X, y in test_iter:\n",
        "    break\n",
        "  trues = get_fashion_mnist_labels(y)\n",
        "  preds = get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
        "  titles = [true +'\\n' + pred for true, pred in zip(trues, preds)] \n",
        "  print(trues)\n",
        "  print(preds)\n",
        "predict_ch3(net, test_iter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGI7gENvERrJ",
        "outputId": "5c390a82-69f6-4371-ab6d-79db23ca919b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ankle boot', 'pullover', 'trouser', 'trouser', 'shirt', 'trouser', 'coat', 'shirt', 'sandal', 'sneaker', 'coat', 'sandal', 'sneaker', 'dress', 'coat', 'trouser', 'pullover', 'coat', 'bag', 't-shirt', 'pullover', 'sandal', 'sneaker', 'ankle boot', 'trouser', 'coat', 'shirt', 't-shirt', 'ankle boot', 'dress', 'bag', 'bag', 'dress', 'dress', 'bag', 't-shirt', 'sneaker', 'sandal', 'sneaker', 'ankle boot', 'shirt', 'trouser', 'dress', 'sneaker', 'shirt', 'sneaker', 'pullover', 'trouser', 'pullover', 'pullover', 'coat', 'coat', 'sandal', 'bag', 'pullover', 'pullover', 'bag', 'coat', 'bag', 't-shirt', 'sneaker', 'sneaker', 'bag', 'sandal', 'trouser', 'trouser', 'pullover', 'dress', 'ankle boot', 'bag', 'sneaker', 't-shirt', 'pullover', 'shirt', 'pullover', 'dress', 'trouser', 'pullover', 'bag', 'coat', 'trouser', 'bag', 'sandal', 'ankle boot', 'sandal', 't-shirt', 'dress', 'pullover', 't-shirt', 'shirt', 'sandal', 'dress', 'shirt', 'sneaker', 'trouser', 'bag', 't-shirt', 'trouser', 'coat', 'pullover', 'dress', 'shirt', 'sneaker', 'pullover', 'sneaker', 'bag', 'sandal', 'ankle boot', 'ankle boot', 'coat', 'pullover', 'sandal', 'sneaker', 't-shirt', 'sandal', 'pullover', 'bag', 'shirt', 'sneaker', 'bag', 't-shirt', 't-shirt', 'ankle boot', 'ankle boot', 'dress', 't-shirt', 'bag', 'coat', 'trouser', 'sandal', 'coat', 'trouser', 'ankle boot', 'trouser', 'bag', 'shirt', 'pullover', 'trouser', 'pullover', 'sandal', 'trouser', 't-shirt', 't-shirt', 't-shirt', 'trouser', 'shirt', 'trouser', 'shirt', 'pullover', 'pullover', 'coat', 'coat', 'trouser', 'coat', 'sandal', 't-shirt', 'coat', 'sneaker', 'ankle boot', 'dress', 'sneaker', 'pullover', 'dress', 'ankle boot', 't-shirt', 'ankle boot', 'coat', 'sneaker', 'coat', 'pullover', 't-shirt', 'sandal', 'pullover', 'trouser', 'pullover', 'trouser', 'dress', 't-shirt', 'ankle boot', 'trouser', 't-shirt', 'ankle boot', 'dress', 'shirt', 'sneaker', 'ankle boot', 'ankle boot', 'coat', 'coat', 'sneaker', 'trouser', 'pullover', 'trouser', 'shirt', 'dress', 'pullover', 'bag', 'dress', 'shirt', 'trouser', 'trouser', 't-shirt', 'pullover', 'ankle boot', 'pullover', 'coat', 't-shirt', 'sneaker', 'ankle boot', 'bag', 'coat', 'trouser', 'bag', 'coat', 'trouser', 'dress', 'trouser', 'shirt', 'sneaker', 'pullover', 'bag', 'sandal', 'pullover', 't-shirt', 'sneaker', 'sneaker', 'shirt', 'pullover', 'sneaker', 't-shirt', 'sneaker', 'bag', 'ankle boot', 'pullover', 'ankle boot', 't-shirt', 'sandal', 'trouser', 'coat', 'coat', 'sandal', 'shirt', 'ankle boot', 'pullover', 'shirt', 'bag', 'shirt', 'coat', 'pullover', 'pullover', 'ankle boot', 'sneaker', 'shirt', 'sandal', 'sandal', 'pullover']\n",
            "['ankle boot', 'pullover', 'trouser', 'trouser', 'shirt', 'trouser', 'coat', 'shirt', 'sandal', 'sneaker', 'coat', 'sandal', 'sandal', 'dress', 'coat', 'trouser', 'pullover', 'pullover', 'bag', 't-shirt', 'pullover', 'sneaker', 'sneaker', 'sneaker', 'trouser', 'pullover', 'shirt', 't-shirt', 'ankle boot', 'coat', 'bag', 'bag', 'dress', 'dress', 'bag', 't-shirt', 'sneaker', 'sandal', 'sneaker', 'ankle boot', 't-shirt', 'trouser', 'dress', 'ankle boot', 'shirt', 'sneaker', 'pullover', 'trouser', 'pullover', 'shirt', 'shirt', 'pullover', 'sandal', 'shirt', 'pullover', 'pullover', 'bag', 'coat', 'bag', 't-shirt', 'sneaker', 'sneaker', 'bag', 'sandal', 'trouser', 'trouser', 't-shirt', 'coat', 'sneaker', 'bag', 'sneaker', 't-shirt', 'shirt', 'shirt', 'pullover', 'dress', 'trouser', 'pullover', 'bag', 'coat', 'trouser', 'bag', 'sandal', 'ankle boot', 'sandal', 't-shirt', 'dress', 'pullover', 't-shirt', 'shirt', 'sandal', 'dress', 'shirt', 'sneaker', 'trouser', 'bag', 't-shirt', 'trouser', 'shirt', 'pullover', 'dress', 'coat', 'sneaker', 'pullover', 'sneaker', 'bag', 'sandal', 'ankle boot', 'ankle boot', 'coat', 'pullover', 'sandal', 'sneaker', 't-shirt', 'sandal', 'pullover', 'bag', 'coat', 'sneaker', 'bag', 't-shirt', 't-shirt', 'ankle boot', 'ankle boot', 'dress', 't-shirt', 'bag', 'coat', 'trouser', 'sandal', 'coat', 'trouser', 'ankle boot', 'trouser', 'bag', 'coat', 'pullover', 'trouser', 'pullover', 'sandal', 'trouser', 't-shirt', 't-shirt', 't-shirt', 'trouser', 'shirt', 'trouser', 'dress', 'pullover', 'pullover', 'shirt', 'pullover', 'trouser', 'dress', 'sandal', 't-shirt', 'coat', 'sneaker', 'ankle boot', 'dress', 'sneaker', 'pullover', 'dress', 'ankle boot', 't-shirt', 'ankle boot', 'coat', 'sneaker', 'coat', 'pullover', 't-shirt', 'sandal', 'pullover', 'trouser', 'pullover', 'trouser', 'dress', 't-shirt', 'ankle boot', 'trouser', 't-shirt', 'ankle boot', 'dress', 'bag', 'sneaker', 'ankle boot', 'ankle boot', 'coat', 'coat', 'sneaker', 'trouser', 'pullover', 'trouser', 'shirt', 'dress', 'pullover', 'bag', 'dress', 'shirt', 'trouser', 'trouser', 't-shirt', 'pullover', 'ankle boot', 'pullover', 'coat', 't-shirt', 'sneaker', 'ankle boot', 'bag', 'coat', 'trouser', 'bag', 'coat', 'trouser', 'dress', 'trouser', 'shirt', 'sneaker', 'coat', 'bag', 'sandal', 'dress', 't-shirt', 'sneaker', 'sneaker', 'shirt', 'shirt', 'sneaker', 't-shirt', 'sneaker', 'bag', 'ankle boot', 'pullover', 'ankle boot', 't-shirt', 'sandal', 'trouser', 'coat', 'pullover', 'sandal', 'coat', 'ankle boot', 'shirt', 'pullover', 'bag', 'shirt', 'coat', 'shirt', 'coat', 'ankle boot', 'sneaker', 'coat', 'sandal', 'sandal', 'coat']\n"
          ]
        }
      ]
    }
  ]
}