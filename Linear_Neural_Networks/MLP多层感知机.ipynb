{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yuchen971/DiveIntoDeepLearning/blob/main/Linear_Neural_Networks/MLP%E5%A4%9A%E5%B1%82%E6%84%9F%E7%9F%A5%E6%9C%BA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVxmmUx5p_Yk"
      },
      "outputs": [],
      "source": [
        "#!pip install d2l\n",
        "#!pip install matplotlib==3.0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDKJGjOYl2Q9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6oweTVcxpnFt"
      },
      "source": [
        "# 手动实现\n",
        "## 初始化"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSvIAC7Epkhd",
        "outputId": "25bec192-09b3-46e8-99b2-1f36f84889be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        }
      ],
      "source": [
        "batch_size = 256\n",
        "# 784 是拉长的图片, 10 是 10 个类别, 256 是一层hidden layer的node数目\n",
        "num_inputs, num_outputs, num_hiddens = 784, 10, 256\n",
        "# nn.parameter()可以用可以不用\n",
        "W1 = nn.Parameter(torch.randn(\n",
        "    num_inputs, num_hiddens, requires_grad=True) * 0.01)\n",
        "b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))\n",
        "# 接受隐藏层, 也就是输入是hidden的node, 输出output\n",
        "W2 = nn.Parameter(torch.randn(\n",
        "    num_hiddens, num_outputs, requires_grad=True) * 0.01)\n",
        "b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))\n",
        "params = [W1, b1, W2, b2]\n",
        "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZb8KleirsaA"
      },
      "source": [
        "# 激活函数, 模型, loss fun"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "id": "MKZj1ZKmrrJG"
      },
      "outputs": [],
      "source": [
        "def relu(X):\n",
        "  a = torch.zeros_like(X)\n",
        "  return torch.max(X, a)\n",
        "\n",
        "def net(X):\n",
        "  X = X.reshape((-1, num_inputs))\n",
        "  H = relu(X@W1 + b1) # @ 矩阵乘法\n",
        "  return (H@W2 + b2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGHRL_vasf_N"
      },
      "source": [
        "# training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "vi2BSai_s_KQ"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_hat, y):\n",
        "  if len(y_hat.shape) > 1 and y_hat.shape[1] > 1:\n",
        "    y_hat = y_hat.argmax(axis=1) # 每行中最大元素的索引来获得预测类别\n",
        "  # 将y_hat的数据类型转换为与y的数据类型, 一个32, 一个64\n",
        "  cmp = y_hat.type(y.dtype) == y \n",
        "  # 将 TRUE, FALSE -> 0, 1\n",
        "  return float(cmp.type(y.dtype).sum()) #return 正确的个数\n",
        "\n",
        "class Accumulator:\n",
        "  '''对n个变量叠加'''\n",
        "  def __init__(self, n):\n",
        "    self.data = [0.0] * n # 初始化n个数\n",
        "  def add(self, *args):\n",
        "    # 元素相加\n",
        "    self.data = [a + float(b) for a, b in zip(self.data, args)]\n",
        "  def reset(self):\n",
        "    self.data = [0.0] * len(self.data)\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx]\n",
        "\n",
        "def evaluate_accuracy(net, data_iter):\n",
        "  if isinstance(net, torch.nn.Module):\n",
        "    net.eval() # 评估模式\n",
        "  metric = Accumulator(2) # 初始化累加的两个参数\n",
        "  with torch.no_grad():\n",
        "    for X, y in data_iter:\n",
        "      # y.numel(): return the length (总数)\n",
        "      metric.add(accuracy(net(X), y), y.numel())\n",
        "  return metric[0] / metric[1] # 正确的个数除以总数\n",
        "\n",
        "def train_epoch_ch3(net, train_iter, loss, updater):\n",
        "  '''训练模型一个迭代周期, updater: optimizer'''\n",
        "  if isinstance(net, torch.nn.Module):\n",
        "    net.train()\n",
        "  # 训练损失总和、训练准确度总和、样本数初始化\n",
        "  metric = Accumulator(3)\n",
        "  for X, y in train_iter:\n",
        "    # 计算梯度\n",
        "    y_hat = net(X) # 预测值输出: ([256, 10])\n",
        "    l = loss(y_hat, y) # cross entropy\n",
        "    if isinstance(updater, torch.optim.Optimizer):\n",
        "      # 使用PyTorch内置的优化器和损失函数\n",
        "      updater.zero_grad()\n",
        "      l.backward()\n",
        "      updater.step()\n",
        "    else:\n",
        "      # 使用定制的优化器和损失函数\n",
        "      l.sum().backward() # l是向量, 转换为标量, pytorch自动转换\n",
        "      updater(X.shape[0]) # X.shape 也就是 batch_size, 因为拉长了\n",
        "    metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
        "  # 返回训练损失和训练精度\n",
        "  return metric[0] / metric [2], metric[1] / metric [2]\n",
        "\n",
        "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):\n",
        "  for epoch in range(num_epochs):\n",
        "    train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
        "    test_acc = evaluate_accuracy(net, test_iter)\n",
        "    train_loss, train_acc = train_metrics\n",
        "    print(f'train_loss = {train_loss}, train_acc = {train_acc}, test_acc = {test_acc}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FQG4Rketr3QM",
        "outputId": "449050d2-db85-4fb5-bda1-681afef9c06c"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train_loss = 0.003144455442329248, train_acc = 0.6976833333333333, test_acc = 0.7695\n",
            "train_loss = 0.0019457713350653648, train_acc = 0.8154166666666667, test_acc = 0.8023\n",
            "train_loss = 0.0016577785536646844, train_acc = 0.84355, test_acc = 0.8009\n",
            "train_loss = 0.0015371723512808482, train_acc = 0.85545, test_acc = 0.8505\n",
            "train_loss = 0.0014393630956610044, train_acc = 0.8643666666666666, test_acc = 0.8168\n",
            "train_loss = 0.0013766879759728907, train_acc = 0.8702166666666666, test_acc = 0.8276\n",
            "train_loss = 0.0013114453750352065, train_acc = 0.87605, test_acc = 0.8464\n",
            "train_loss = 0.0012177885269125303, train_acc = 0.8845333333333333, test_acc = 0.8678\n",
            "train_loss = 0.0011908627289036909, train_acc = 0.8867666666666667, test_acc = 0.8461\n"
          ]
        }
      ],
      "source": [
        "num_epochs, lr = 10, 0.5\n",
        "loss = nn.CrossEntropyLoss(reduction='mean')\n",
        "updater = torch.optim.SGD(params, lr=lr)\n",
        "train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "MLP多层感知机.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNmjL4lcv2AvvMdnxcbF1hK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}